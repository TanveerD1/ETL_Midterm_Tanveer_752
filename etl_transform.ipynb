{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a67a9e4",
   "metadata": {},
   "source": [
    "# ETL Transformation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146bc4dd",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7efbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f07733",
   "metadata": {},
   "source": [
    "## Load extracted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e46752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 raw records and 10 incremental records\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv('data/raw_data.csv')\n",
    "incrementalData = pd.read_csv('data/incremental_data.csv')\n",
    "print(f\"Loaded {len(rawData)} raw records and {len(incrementalData)} incremental records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac021330",
   "metadata": {},
   "source": [
    "## Transfromation 1: Cleaning missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2345aae8",
   "metadata": {},
   "source": [
    "#### Creating compies for Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d4e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawCleaned = rawData.copy()\n",
    "incCleaned = incrementalData.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b30665",
   "metadata": {},
   "source": [
    "#### Before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4253d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data - Missing values: 88\n",
      "Raw data - Duplicates: 1\n",
      "Incremental data - Missing values: 12\n"
     ]
    }
   ],
   "source": [
    "print(f\"Raw data - Missing values: {rawData.isnull().sum().sum()}\")\n",
    "print(f\"Raw data - Duplicates: {rawData.duplicated().sum()}\")\n",
    "print(f\"Incremental data - Missing values: {incrementalData.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c33c1be",
   "metadata": {},
   "source": [
    "#### Missing cutomer names\n",
    "- change the missing names to Unknown for both raw and incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eca79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawCleaned['customer_name'].fillna('Unknown_Customer', inplace=True)\n",
    "incCleaned['customer_name'].fillna('Unknown_Customer', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019a74c",
   "metadata": {},
   "source": [
    "#### Imputing missing quantities for raw data using median\n",
    "- this is beacause median values are less affected by outliers\n",
    "- calculates the median of the quantity column and fills missing values with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1db9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in rawCleaned['product'].unique():\n",
    "    product_median_qty = rawCleaned[rawCleaned['product'] == product]['quantity'].median()\n",
    "    rawCleaned.loc[(rawCleaned['product'] == product) & (rawCleaned['quantity'].isna()), 'quantity'] = product_median_qty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa1f9f4",
   "metadata": {},
   "source": [
    "#### Imputing missing values for incremental data using median \n",
    "- used the same logic as above\n",
    "- calculates the median of the quantity column and fills missing values with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db6f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in incCleaned['product'].unique():\n",
    "    product_median_qty = incCleaned[incCleaned['product'] == product]['quantity'].median()\n",
    "    incCleaned.loc[(incCleaned['product'] == product) & (incCleaned['quantity'].isna()), 'quantity'] = product_median_qty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1021a75f",
   "metadata": {},
   "source": [
    "#### missing unit prices using median\n",
    "- first created a price mapping dictionary to hold the median prices for each product\n",
    "- used the apply() logic to replace missing unit prices with the median price for that product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e75fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_map = rawCleaned.groupby('product')['unit_price'].median().to_dict()\n",
    "rawCleaned['unit_price'] = rawCleaned.apply(\n",
    "    lambda row: price_map[row['product']] if pd.isna(row['unit_price']) else row['unit_price'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad755bf",
   "metadata": {},
   "source": [
    "#### Missing regions\n",
    "- created most common region mapping dictionary using the mode() function\n",
    "- used the fillna() function to replace missing regions with the most common region for that product\n",
    "- applied this to both raw and incremental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee274c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping\n",
    "region_map = rawCleaned.dropna().groupby('customer_name')['region'].agg(lambda x: x.mode()[0] if not x.mode().empty else 'Unknown').to_dict()\n",
    "# Fill missing regions\n",
    "rawCleaned['region'] = rawCleaned['region'].fillna(rawCleaned['customer_name'].map(region_map)).fillna('Unknown')\n",
    "incCleaned['region'] = incCleaned['region'].fillna('Central')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11130df0",
   "metadata": {},
   "source": [
    "#### Removing Exact Duplicates\n",
    "- using the drop_duplicates() function to remove exact duplicates from both raw and incremental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe46992",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawCleaned.drop_duplicates(inplace=True)\n",
    "incCleaned.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5965a7",
   "metadata": {},
   "source": [
    "#### Cleaning verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c6de77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data - Missing values: 1\n",
      "Raw data - Duplicates: 0\n",
      "Raw data - Records: 100 → 99\n"
     ]
    }
   ],
   "source": [
    "print(f\"Raw data - Missing values: {rawCleaned.isnull().sum().sum()}\")\n",
    "print(f\"Raw data - Duplicates: {rawCleaned.duplicated().sum()}\")\n",
    "print(f\"Raw data - Records: {len(rawData)} → {len(rawCleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d4ae55",
   "metadata": {},
   "source": [
    "## Transfromation 2: Data Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d35bb2",
   "metadata": {},
   "source": [
    "#### Feature Engineering: Adding total price columns to botb raw and incremental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48503016",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawCleaned['total_price'] = rawCleaned['quantity'] * rawCleaned['unit_price']\n",
    "incCleaned['total_price'] = incCleaned['quantity'] * incCleaned['unit_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b702f",
   "metadata": {},
   "source": [
    "#### Adding a price ordering column, to sort prices from low to high, called it Price_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "320a87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_order_value(total_price):\n",
    "    if pd.isna(total_price):\n",
    "        return 'Unknown'\n",
    "    elif total_price < 500:\n",
    "        return 'Low'\n",
    "    elif total_price < 1500:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "rawCleaned['price_range'] = rawCleaned['total_price'].apply(categorize_order_value)\n",
    "incCleaned['price_range'] = incCleaned['total_price'].apply(categorize_order_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee95bc",
   "metadata": {},
   "source": [
    "## Transformation 3: Structural Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa51ace",
   "metadata": {},
   "source": [
    "#### looking at Data-Types\n",
    "- we can see order date is an object, which needs to change\n",
    "- we need to change datatypes for standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54766f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id           int64\n",
      "customer_name     object\n",
      "product           object\n",
      "quantity         float64\n",
      "unit_price       float64\n",
      "order_date        object\n",
      "region            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(rawData.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab24ba29",
   "metadata": {},
   "source": [
    "#### converting to Datetimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5276a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawCleaned['order_date'] = pd.to_datetime(rawCleaned['order_date'])\n",
    "incCleaned['order_date'] = pd.to_datetime(incCleaned['order_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e3fc1",
   "metadata": {},
   "source": [
    "#### Rounding off Numerical data to 2 decimal places\n",
    "- this is done to standardize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawCleaned['unit_price'] = rawCleaned['unit_price'].round(2)\n",
    "rawCleaned['total_price'] = rawCleaned['total_price'].round(2)\n",
    "incCleaned['unit_price'] = incCleaned['unit_price'].round(2)\n",
    "incCleaned['total_price'] = incCleaned['total_price'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae1a8e",
   "metadata": {},
   "source": [
    "#### Text Standardization\n",
    "- removing whitespace\n",
    "- capitalizing names\n",
    "- capitalizing all region names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "889bbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawCleaned['customer_name'] = rawCleaned['customer_name'].str.strip().str.title()\n",
    "rawCleaned['product'] = rawCleaned['product'].str.strip().str.title()\n",
    "rawCleaned['region'] = rawCleaned['region'].str.strip().str.upper()\n",
    "\n",
    "incCleaned['customer_name'] = incCleaned['customer_name'].str.strip().str.title()\n",
    "incCleaned['product'] = incCleaned['product'].str.strip().str.title()\n",
    "incCleaned['region'] = incCleaned['region'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5881321",
   "metadata": {},
   "source": [
    "## Transformation 4: Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370cde47",
   "metadata": {},
   "source": [
    "#### Dropping irrelevant columns\n",
    "- after looking at the data, i believe price range is unncecessary\n",
    "- dropping price range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2599443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rawCleaned columns: ['order_id', 'customer_name', 'product', 'quantity', 'unit_price', 'order_date', 'region', 'total_price', 'price_range']\n"
     ]
    }
   ],
   "source": [
    "print(\"rawCleaned columns:\", rawCleaned.columns.tolist())\n",
    "rawCleaned = rawCleaned.drop(columns=['price_range'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c0c91",
   "metadata": {},
   "source": [
    "#### Filtering Unealistic values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0882dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawCleaned = rawCleaned[(rawCleaned['quantity'] > 0) & (rawCleaned['unit_price'] > 0)]\n",
    "incCleaned = incCleaned[(incCleaned['quantity'] > 0) & (incCleaned['unit_price'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d605b",
   "metadata": {},
   "source": [
    "## Transformation 5: Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f716b6d",
   "metadata": {},
   "source": [
    "#### Region Categorization\n",
    "- creating a region mapping dictionary to categorize regions to specify the nortrhern region, southern region, eastern region, and western region\n",
    "- using the map() function to apply this mapping to the region column in both raw and incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55974528",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_groups = {\n",
    "    'NORTH': 'Northern_Region',\n",
    "    'SOUTH': 'Southern_Region',\n",
    "    'EAST': 'Eastern_Region', \n",
    "    'WEST': 'Western_Region',\n",
    "    'CENTRAL': 'Central_Region',\n",
    "    'UNKNOWN': 'Unassigned'\n",
    "}\n",
    "rawCleaned['region_group'] = rawCleaned['region'].map(region_groups)\n",
    "incCleaned['region_group'] = incCleaned['region'].map(region_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a3dba",
   "metadata": {},
   "source": [
    "#### Customer Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dd62da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_order_counts = rawCleaned['customer_name'].value_counts().to_dict()\n",
    "rawCleaned['customer_order_frequency'] = rawCleaned['customer_name'].map(customer_order_counts)\n",
    "\n",
    "def categorize_customer_tier(frequency):\n",
    "    if frequency >= 10:\n",
    "        return 'VIP'\n",
    "    elif frequency >= 5:\n",
    "        return 'Loyal'\n",
    "    elif frequency >= 2:\n",
    "        return 'Regular'\n",
    "    else:\n",
    "        return 'New'\n",
    "\n",
    "rawCleaned['customer_tier'] = rawCleaned['customer_order_frequency'].apply(categorize_customer_tier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb21ae",
   "metadata": {},
   "source": [
    "## Saving Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff371a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawCleaned.to_csv('transformed/transformed_full.csv', index=False)\n",
    "incCleaned.to_csv('transformed/transformed_incremental.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae82fc8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
