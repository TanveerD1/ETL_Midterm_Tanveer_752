{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a04fef0",
   "metadata": {},
   "source": [
    "# ETL Load Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c398ee0",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e7b8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0344b2",
   "metadata": {},
   "source": [
    "#### Loading Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id customer_name product  quantity  unit_price  order_date region  \\\n",
      "0         1         Diana  Tablet       2.0       500.0  2024-01-20  SOUTH   \n",
      "1         2           Eve  Laptop       2.0       250.0  2024-04-29  NORTH   \n",
      "2         3       Charlie  Laptop       2.0       250.0  2024-01-08   WEST   \n",
      "3         4           Eve  Laptop       2.0       750.0  2024-01-07   WEST   \n",
      "4         5           Eve  Tablet       3.0       500.0  2024-03-07  SOUTH   \n",
      "\n",
      "   total_price     region_group  customer_order_frequency customer_tier  \n",
      "0       1000.0  Southern_Region                        24           VIP  \n",
      "1        500.0  Northern_Region                        17           VIP  \n",
      "2        500.0   Western_Region                        11           VIP  \n",
      "3       1500.0   Western_Region                        17           VIP  \n",
      "4       1500.0  Southern_Region                        17           VIP  \n"
     ]
    }
   ],
   "source": [
    "transformed_full = pd.read_csv('transformed/transformed_full.csv') # Load the full transformed dataset\n",
    "transformed_incremental = pd.read_csv('transformed/transformed_incremental.csv') # Load the incremental transformed dataset\n",
    "print(transformed_full.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0782b",
   "metadata": {},
   "source": [
    "#### Create Database storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('loaded', exist_ok=True) # Create the 'loaded' directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789084a",
   "metadata": {},
   "source": [
    "#### Creating SQL database for full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7960a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_full = create_engine('sqlite:///loaded/full_data.db') # Create a SQLite engine for the full dataset\n",
    "transformed_full.to_sql('full_data', engine_full, if_exists='replace', index=False) # Load the full dataset into the SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916e99a",
   "metadata": {},
   "source": [
    "#### Creatung SQL database for incremental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b802b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_incremental = create_engine('sqlite:///loaded/incremental_data.db') # Create a SQLite engine for the incremental dataset\n",
    "transformed_incremental.to_sql('full_data', engine_incremental, if_exists='replace', index=False) # Load the incremental dataset into the SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a86e01",
   "metadata": {},
   "source": [
    "## Querying the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af6c2b5",
   "metadata": {},
   "source": [
    "#### VErifying connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_full = sqlite3.connect('loaded/full_data.db') # Connect to the full dataset SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699e021f",
   "metadata": {},
   "source": [
    "#### Verification Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591fa471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records from full database:\n",
      "   order_id customer_name product  quantity  unit_price  order_date region  \\\n",
      "0         1         Diana  Tablet       2.0       500.0  2024-01-20  SOUTH   \n",
      "1         2           Eve  Laptop       2.0       250.0  2024-04-29  NORTH   \n",
      "2         3       Charlie  Laptop       2.0       250.0  2024-01-08   WEST   \n",
      "3         4           Eve  Laptop       2.0       750.0  2024-01-07   WEST   \n",
      "4         5           Eve  Tablet       3.0       500.0  2024-03-07  SOUTH   \n",
      "\n",
      "   total_price     region_group  customer_order_frequency customer_tier  \n",
      "0       1000.0  Southern_Region                        24           VIP  \n",
      "1        500.0  Northern_Region                        17           VIP  \n",
      "2        500.0   Western_Region                        11           VIP  \n",
      "3       1500.0   Western_Region                        17           VIP  \n",
      "4       1500.0  Southern_Region                        17           VIP  \n"
     ]
    }
   ],
   "source": [
    "verification_query = \"SELECT * FROM full_data LIMIT 5\" # Query to verify the data , from the exam requirements\n",
    "verification_result = pd.read_sql_query(verification_query, conn_full) # Execute the query and load the first 5 records into a DataFrame\n",
    "print(\"First 5 records from full database:\")\n",
    "print(verification_result)# Print the verification result\n",
    "verification_result.to_csv('loaded/verification_sample.csv', index=False) # Save the verification result to a CSV file(part of the exam requirements)\n",
    "conn_full.close()# Close the connection to the full dataset database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7597b055",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
